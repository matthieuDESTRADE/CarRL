{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "from environment import TorchLikeCarEnv, CarEnv\n",
    "%aimport environment\n",
    "from policy import QNetwork, recover_flattened\n",
    "%aimport policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Evotorch RL example](https://github.com/nnaisense/evotorch?tab=readme-ov-file#a-reinforcement-learning-example)\n",
    "In a GymNE problem, the solver tries to maximize the total reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from evotorch.algorithms import CMAES, CEM\n",
    "from evotorch.logging import StdOutLogger, PicklingLogger\n",
    "from evotorch.neuroevolution import GymNE\n",
    "\n",
    "def gymNE_env(*args, **kwargs): return TorchLikeCarEnv(10, False, evaluation=False, *args, **kwargs)\n",
    "action_dim = gymNE_env().action_space.n\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-10 20:50:53] INFO     <13036> evotorch.core: Instance of `GymNE` (id:1805835953488) -- The `dtype` for the problem's decision variables is set as torch.float32\n",
      "[2024-03-10 20:50:53] INFO     <13036> evotorch.core: Instance of `GymNE` (id:1805835953488) -- `eval_dtype` (the dtype of the fitnesses and evaluation data) is set as torch.float32\n",
      "[2024-03-10 20:50:53] INFO     <13036> evotorch.core: Instance of `GymNE` (id:1805835953488) -- The `device` of the problem is set as cpu\n",
      "[2024-03-10 20:50:53] INFO     <13036> evotorch.core: Instance of `GymNE` (id:1805835953488) -- The number of actors that will be allocated for parallelized evaluation is 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m PicklingLogger(searcher, interval\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, directory\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEA_results\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[39m# Run the algorithm for the specified amount of generations\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m searcher\u001b[39m.\u001b[39;49mrun(\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\algorithms\\searchalgorithm.py:425\u001b[0m, in \u001b[0;36mSearchAlgorithm.run\u001b[1;34m(self, num_generations, reset_first_step_datetime)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_first_step_datetime()\n\u001b[0;32m    424\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mint\u001b[39m(num_generations)):\n\u001b[1;32m--> 425\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    427\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_of_run_hook) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    428\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_of_run_hook(\u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus))\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\algorithms\\searchalgorithm.py:390\u001b[0m, in \u001b[0;36mSearchAlgorithm.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_step_datetime \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_step_datetime \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m--> 390\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step()\n\u001b[0;32m    391\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    392\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_status({\u001b[39m\"\u001b[39m\u001b[39miter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_count})\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\algorithms\\distributed\\gaussian.py:354\u001b[0m, in \u001b[0;36mGaussianSearchAlgorithm._step_non_distributed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_population \u001b[39m=\u001b[39m SolutionBatch\u001b[39m.\u001b[39mcat(populations)\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_iter:\n\u001b[0;32m    352\u001b[0m     \u001b[39m# If we are computing the first generation, we just sample from our distribution and evaluate\u001b[39;00m\n\u001b[0;32m    353\u001b[0m     \u001b[39m# the solutions.\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m     fill_and_eval_pop()\n\u001b[0;32m    355\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_iter \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[39m# If we are computing next generations, then we need to compute the gradients of the last\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[39m# generation, sample a new population, and evaluate the new population's solutions.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\algorithms\\distributed\\gaussian.py:295\u001b[0m, in \u001b[0;36mGaussianSearchAlgorithm._step_non_distributed.<locals>.fill_and_eval_pop\u001b[1;34m()\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution\u001b[39m.\u001b[39msample(out\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_population\u001b[39m.\u001b[39maccess_values(), generator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem)\n\u001b[0;32m    294\u001b[0m     \u001b[39m# Finally, here, the solutions are evaluated.\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproblem\u001b[39m.\u001b[39;49mevaluate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_population)\n\u001b[0;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m     \u001b[39m# If num_interactions is not None, then this means that we have a threshold for the number\u001b[39;00m\n\u001b[0;32m    298\u001b[0m     \u001b[39m# of simulator interactions to reach before declaring the phase of sampling complete.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[39m# Therefore, to properly count the simulator interactions we made during this generation, we need\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[39m# to get the interaction count before starting our sampling and evaluation operations.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m     first_num_interactions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem\u001b[39m.\u001b[39mstatus\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtotal_interaction_count\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\core.py:2548\u001b[0m, in \u001b[0;36mProblem.evaluate\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   2544\u001b[0m must_sync_after \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sync_before()\n\u001b[0;32m   2546\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_preparations()\n\u001b[1;32m-> 2548\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_all(batch)\n\u001b[0;32m   2550\u001b[0m \u001b[39mif\u001b[39;00m must_sync_after:\n\u001b[0;32m   2551\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sync_after()\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\core.py:2566\u001b[0m, in \u001b[0;36mProblem._evaluate_all\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m   2564\u001b[0m fitness_device \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device_of_fitness_function()\n\u001b[0;32m   2565\u001b[0m \u001b[39mif\u001b[39;00m fitness_device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2566\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_batch(batch)\n\u001b[0;32m   2567\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2568\u001b[0m     original_device \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mdevice\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\core.py:2600\u001b[0m, in \u001b[0;36mProblem._evaluate_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m   2598\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2599\u001b[0m     \u001b[39mfor\u001b[39;00m sln \u001b[39min\u001b[39;00m batch:\n\u001b[1;32m-> 2600\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate(sln)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\neproblem.py:424\u001b[0m, in \u001b[0;36mNEProblem._evaluate\u001b[1;34m(self, solution)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     evaluator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_eval_func\n\u001b[1;32m--> 424\u001b[0m fitnesses \u001b[39m=\u001b[39m evaluator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparameterize_net(parameters))\n\u001b[0;32m    426\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fitnesses, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    427\u001b[0m     solution\u001b[39m.\u001b[39mset_evals(\u001b[39m*\u001b[39mfitnesses)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\gymne.py:637\u001b[0m, in \u001b[0;36mGymNE._evaluate_network\u001b[1;34m(self, policy)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_evaluate_network\u001b[39m(\u001b[39mself\u001b[39m, policy: nn\u001b[39m.\u001b[39mModule) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[\u001b[39mfloat\u001b[39m, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 637\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m    638\u001b[0m         policy,\n\u001b[0;32m    639\u001b[0m         update_stats\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    640\u001b[0m         visualize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    641\u001b[0m         num_episodes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_episodes,\n\u001b[0;32m    642\u001b[0m         decrease_rewards_by\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decrease_rewards_by,\n\u001b[0;32m    643\u001b[0m     )\n\u001b[0;32m    644\u001b[0m     \u001b[39mreturn\u001b[39;00m result[\u001b[39m\"\u001b[39m\u001b[39mcumulative_reward\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\gymne.py:462\u001b[0m, in \u001b[0;36mGymNE.run\u001b[1;34m(self, policy, update_stats, visualize, num_episodes, decrease_rewards_by)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     policy\u001b[39m.\u001b[39meval()\n\u001b[1;32m--> 462\u001b[0m     episode_results \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rollout(\n\u001b[0;32m    464\u001b[0m             policy\u001b[39m=\u001b[39;49mpolicy,\n\u001b[0;32m    465\u001b[0m             update_stats\u001b[39m=\u001b[39;49mupdate_stats,\n\u001b[0;32m    466\u001b[0m             visualize\u001b[39m=\u001b[39;49mvisualize,\n\u001b[0;32m    467\u001b[0m             decrease_rewards_by\u001b[39m=\u001b[39;49mdecrease_rewards_by,\n\u001b[0;32m    468\u001b[0m         )\n\u001b[0;32m    469\u001b[0m         \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(num_episodes)\n\u001b[0;32m    470\u001b[0m     ]\n\u001b[0;32m    472\u001b[0m     results \u001b[39m=\u001b[39m _accumulate_all_across_dicts(episode_results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_keys)\n\u001b[0;32m    473\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\gymne.py:463\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     policy\u001b[39m.\u001b[39meval()\n\u001b[0;32m    462\u001b[0m     episode_results \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rollout(\n\u001b[0;32m    464\u001b[0m             policy\u001b[39m=\u001b[39;49mpolicy,\n\u001b[0;32m    465\u001b[0m             update_stats\u001b[39m=\u001b[39;49mupdate_stats,\n\u001b[0;32m    466\u001b[0m             visualize\u001b[39m=\u001b[39;49mvisualize,\n\u001b[0;32m    467\u001b[0m             decrease_rewards_by\u001b[39m=\u001b[39;49mdecrease_rewards_by,\n\u001b[0;32m    468\u001b[0m         )\n\u001b[0;32m    469\u001b[0m         \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_episodes)\n\u001b[0;32m    470\u001b[0m     ]\n\u001b[0;32m    472\u001b[0m     results \u001b[39m=\u001b[39m _accumulate_all_across_dicts(episode_results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_keys)\n\u001b[0;32m    473\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\gymne.py:391\u001b[0m, in \u001b[0;36mGymNE._rollout\u001b[1;34m(self, policy, update_stats, visualize, decrease_rewards_by)\u001b[0m\n\u001b[0;32m    388\u001b[0m cumulative_reward \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m    390\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m     observation, raw_reward, done, info \u001b[39m=\u001b[39m take_step_in_env(env, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_use_policy(observation, policy))\n\u001b[0;32m    392\u001b[0m     reward \u001b[39m=\u001b[39m raw_reward \u001b[39m-\u001b[39m decrease_rewards_by\n\u001b[0;32m    393\u001b[0m     t \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\gymne.py:336\u001b[0m, in \u001b[0;36mGymNE._use_policy\u001b[1;34m(self, observation, policy)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_use_policy\u001b[39m(\u001b[39mself\u001b[39m, observation: Iterable, policy: nn\u001b[39m.\u001b[39mModule) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterable:\n\u001b[0;32m    335\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 336\u001b[0m         result \u001b[39m=\u001b[39m policy(torch\u001b[39m.\u001b[39;49mas_tensor(observation, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32, device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m))\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    337\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action_noise_stdev \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m         result \u001b[39m=\u001b[39m (\n\u001b[0;32m    339\u001b[0m             result\n\u001b[0;32m    340\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_gaussian(\u001b[39mlen\u001b[39m(result), center\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, stdev\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action_noise_stdev, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    341\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\net\\statefulmodule.py:59\u001b[0m, in \u001b[0;36mStatefulModule.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m     57\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hidden \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m         \u001b[39m# If there is no stored hidden state, then only pass the input tensor to the wrapped module.\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrapped_module(x)\n\u001b[0;32m     60\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m         \u001b[39m# If there is a hidden state saved from the previous call to this `forward(...)` method, then pass the\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[39m# input tensor and this stored hidden state.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrapped_module(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hidden)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\policy.py:45\u001b[0m, in \u001b[0;36mQNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1(x)\n\u001b[0;32m     44\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(x)\n\u001b[1;32m---> 45\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)\n\u001b[0;32m     46\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu2(x)\n\u001b[0;32m     47\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool2(x)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "q_network = QNetwork(action_dim).to(device)\n",
    "problem = GymNE(\n",
    "    env=gymNE_env,\n",
    "    network=q_network,\n",
    "    num_episodes=1,\n",
    ")\n",
    "\n",
    "searcher = CEM(\n",
    "    problem,\n",
    "    # The keyword arguments below refer to hyperparameters specific to the\n",
    "    # cross entropy method algorithm. It is recommended to tune these\n",
    "    # hyperparameters according to the problem at hand.\n",
    "    popsize=15,  # population size\n",
    "    parenthood_ratio=0.3,  # better solutions become parents\n",
    "    stdev_init=10.0,  # initial standard deviation of the search distribution\n",
    ")\n",
    "\n",
    "# Instantiate a standard output logger\n",
    "StdOutLogger(searcher)\n",
    "\n",
    "# Optional: Instantiate a logger to pickle and save the results periodically.\n",
    "# In this example, among the saved results will be the center of the search\n",
    "# distribution, since we are using PGPE which is distribution-based.\n",
    "PicklingLogger(searcher, interval=10, directory=\"EA_results\")\n",
    "\n",
    "# Run the algorithm for the specified amount of generations\n",
    "searcher.run(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-10 18:06:06] INFO     <11760> evotorch.core: Instance of `GymNE` (id:1674915931152) -- The `dtype` for the problem's decision variables is set as torch.float32\n",
      "[2024-03-10 18:06:06] INFO     <11760> evotorch.core: Instance of `GymNE` (id:1674915931152) -- `eval_dtype` (the dtype of the fitnesses and evaluation data) is set as torch.float32\n",
      "[2024-03-10 18:06:06] INFO     <11760> evotorch.core: Instance of `GymNE` (id:1674915931152) -- The `device` of the problem is set as cpu\n",
      "[2024-03-10 18:06:06] INFO     <11760> evotorch.core: Instance of `GymNE` (id:1674915931152) -- The number of actors that will be allocated for parallelized evaluation is 0\n",
      "                   iter : 1\n",
      "              mean_eval : 0.04982553794980049\n",
      "          pop_best_eval : 10.844755172729492\n",
      "            median_eval : 3.2594640254974365\n",
      "              best_eval : 10.844755172729492\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 898\n",
      "    total_episode_count : 20\n",
      "\n",
      "                   iter : 2\n",
      "              mean_eval : -0.12056197971105576\n",
      "          pop_best_eval : 8.998655319213867\n",
      "            median_eval : -1.8864582777023315\n",
      "              best_eval : 10.844755172729492\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 1724\n",
      "    total_episode_count : 40\n",
      "\n",
      "                   iter : 3\n",
      "              mean_eval : 5.3089447021484375\n",
      "          pop_best_eval : 26.533119201660156\n",
      "            median_eval : 5.574542045593262\n",
      "              best_eval : 26.533119201660156\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 2643\n",
      "    total_episode_count : 60\n",
      "\n",
      "                   iter : 4\n",
      "              mean_eval : -0.07128741592168808\n",
      "          pop_best_eval : 12.89936637878418\n",
      "            median_eval : -2.4105753898620605\n",
      "              best_eval : 26.533119201660156\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 3481\n",
      "    total_episode_count : 80\n",
      "\n",
      "                   iter : 5\n",
      "              mean_eval : 5.829281806945801\n",
      "          pop_best_eval : 55.566280364990234\n",
      "            median_eval : 4.384042263031006\n",
      "              best_eval : 55.566280364990234\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 4528\n",
      "    total_episode_count : 100\n",
      "\n",
      "                   iter : 6\n",
      "              mean_eval : 3.759063720703125\n",
      "          pop_best_eval : 11.128018379211426\n",
      "            median_eval : 6.028505802154541\n",
      "              best_eval : 55.566280364990234\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 5437\n",
      "    total_episode_count : 120\n",
      "\n",
      "                   iter : 7\n",
      "              mean_eval : 9.76563835144043\n",
      "          pop_best_eval : 69.3368148803711\n",
      "            median_eval : 4.432125091552734\n",
      "              best_eval : 69.3368148803711\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 6678\n",
      "    total_episode_count : 140\n",
      "\n",
      "                   iter : 8\n",
      "              mean_eval : 9.20088005065918\n",
      "          pop_best_eval : 105.9648666381836\n",
      "            median_eval : 4.593688488006592\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 7800\n",
      "    total_episode_count : 160\n",
      "\n",
      "                   iter : 9\n",
      "              mean_eval : 7.476925849914551\n",
      "          pop_best_eval : 70.55776977539062\n",
      "            median_eval : 6.661575794219971\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 9193\n",
      "    total_episode_count : 180\n",
      "\n",
      "                   iter : 10\n",
      "              mean_eval : 10.87798023223877\n",
      "          pop_best_eval : 70.65438842773438\n",
      "            median_eval : 4.488537311553955\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 10626\n",
      "    total_episode_count : 200\n",
      "\n",
      "                   iter : 11\n",
      "              mean_eval : 6.499405860900879\n",
      "          pop_best_eval : 28.238906860351562\n",
      "            median_eval : 6.973263740539551\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 11680\n",
      "    total_episode_count : 220\n",
      "\n",
      "                   iter : 12\n",
      "              mean_eval : 10.581979751586914\n",
      "          pop_best_eval : 85.50794219970703\n",
      "            median_eval : 5.153702259063721\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 12942\n",
      "    total_episode_count : 240\n",
      "\n",
      "                   iter : 13\n",
      "              mean_eval : 11.06602668762207\n",
      "          pop_best_eval : 67.7269287109375\n",
      "            median_eval : 6.010682582855225\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 14102\n",
      "    total_episode_count : 260\n",
      "\n",
      "                   iter : 14\n",
      "              mean_eval : 6.098099708557129\n",
      "          pop_best_eval : 23.740924835205078\n",
      "            median_eval : 6.290831089019775\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 15100\n",
      "    total_episode_count : 280\n",
      "\n",
      "                   iter : 15\n",
      "              mean_eval : 12.596197128295898\n",
      "          pop_best_eval : 60.621280670166016\n",
      "            median_eval : 6.5009989738464355\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 16546\n",
      "    total_episode_count : 300\n",
      "\n",
      "                   iter : 16\n",
      "              mean_eval : 16.090961456298828\n",
      "          pop_best_eval : 92.76439666748047\n",
      "            median_eval : 7.757014274597168\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 18032\n",
      "    total_episode_count : 320\n",
      "\n",
      "                   iter : 17\n",
      "              mean_eval : 11.638312339782715\n",
      "          pop_best_eval : 43.21437072753906\n",
      "            median_eval : 7.851982116699219\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 19331\n",
      "    total_episode_count : 340\n",
      "\n",
      "                   iter : 18\n",
      "              mean_eval : 11.80453109741211\n",
      "          pop_best_eval : 63.137786865234375\n",
      "            median_eval : 8.50796127319336\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 20572\n",
      "    total_episode_count : 360\n",
      "\n",
      "                   iter : 19\n",
      "              mean_eval : 15.115518569946289\n",
      "          pop_best_eval : 66.95719146728516\n",
      "            median_eval : 9.138301849365234\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 21950\n",
      "    total_episode_count : 380\n",
      "\n",
      "                   iter : 20\n",
      "              mean_eval : 14.661747932434082\n",
      "          pop_best_eval : 70.5242919921875\n",
      "            median_eval : 8.7377290725708\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 23488\n",
      "    total_episode_count : 400\n",
      "\n",
      "                   iter : 21\n",
      "              mean_eval : 20.882389068603516\n",
      "          pop_best_eval : 82.42039489746094\n",
      "            median_eval : 8.088264465332031\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 25166\n",
      "    total_episode_count : 420\n",
      "\n",
      "                   iter : 22\n",
      "              mean_eval : 31.236730575561523\n",
      "          pop_best_eval : 97.71922302246094\n",
      "            median_eval : 22.975717544555664\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 27575\n",
      "    total_episode_count : 440\n",
      "\n",
      "                   iter : 23\n",
      "              mean_eval : 14.414471626281738\n",
      "          pop_best_eval : 43.597660064697266\n",
      "            median_eval : 7.569087505340576\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 28906\n",
      "    total_episode_count : 460\n",
      "\n",
      "                   iter : 24\n",
      "              mean_eval : 16.76059913635254\n",
      "          pop_best_eval : 78.4247055053711\n",
      "            median_eval : 6.241520881652832\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 30378\n",
      "    total_episode_count : 480\n",
      "\n",
      "                   iter : 25\n",
      "              mean_eval : 21.327730178833008\n",
      "          pop_best_eval : 69.11101531982422\n",
      "            median_eval : 13.117871284484863\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 32174\n",
      "    total_episode_count : 500\n",
      "\n",
      "                   iter : 26\n",
      "              mean_eval : 12.058351516723633\n",
      "          pop_best_eval : 41.32778549194336\n",
      "            median_eval : 6.905976295471191\n",
      "              best_eval : 105.9648666381836\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 33427\n",
      "    total_episode_count : 520\n",
      "\n",
      "                   iter : 27\n",
      "              mean_eval : 21.504268646240234\n",
      "          pop_best_eval : 107.75101470947266\n",
      "            median_eval : 11.008405685424805\n",
      "              best_eval : 107.75101470947266\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 35191\n",
      "    total_episode_count : 540\n",
      "\n",
      "                   iter : 28\n",
      "              mean_eval : 15.209320068359375\n",
      "          pop_best_eval : 93.16949462890625\n",
      "            median_eval : 9.425811767578125\n",
      "              best_eval : 107.75101470947266\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 36600\n",
      "    total_episode_count : 560\n",
      "\n",
      "                   iter : 29\n",
      "              mean_eval : 23.09023666381836\n",
      "          pop_best_eval : 107.38607025146484\n",
      "            median_eval : 7.173940181732178\n",
      "              best_eval : 107.75101470947266\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 38484\n",
      "    total_episode_count : 580\n",
      "\n",
      "                   iter : 30\n",
      "              mean_eval : 20.017244338989258\n",
      "          pop_best_eval : 54.84218215942383\n",
      "            median_eval : 19.07754898071289\n",
      "              best_eval : 107.75101470947266\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 40347\n",
      "    total_episode_count : 600\n",
      "\n",
      "                   iter : 31\n",
      "              mean_eval : 21.817636489868164\n",
      "          pop_best_eval : 106.94405364990234\n",
      "            median_eval : 9.391530990600586\n",
      "              best_eval : 107.75101470947266\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 42224\n",
      "    total_episode_count : 620\n",
      "\n",
      "                   iter : 32\n",
      "              mean_eval : 23.58711814880371\n",
      "          pop_best_eval : 74.18291473388672\n",
      "            median_eval : 11.737768173217773\n",
      "              best_eval : 107.75101470947266\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 44123\n",
      "    total_episode_count : 640\n",
      "\n",
      "                   iter : 33\n",
      "              mean_eval : 13.960929870605469\n",
      "          pop_best_eval : 41.4915885925293\n",
      "            median_eval : 11.316167831420898\n",
      "              best_eval : 107.75101470947266\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 45488\n",
      "    total_episode_count : 660\n",
      "\n",
      "                   iter : 34\n",
      "              mean_eval : 22.238019943237305\n",
      "          pop_best_eval : 107.90327453613281\n",
      "            median_eval : 7.8746232986450195\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 47274\n",
      "    total_episode_count : 680\n",
      "\n",
      "                   iter : 35\n",
      "              mean_eval : 22.01898193359375\n",
      "          pop_best_eval : 107.84361267089844\n",
      "            median_eval : 6.901859760284424\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 48987\n",
      "    total_episode_count : 700\n",
      "\n",
      "                   iter : 36\n",
      "              mean_eval : 14.571922302246094\n",
      "          pop_best_eval : 91.16405487060547\n",
      "            median_eval : 8.114922523498535\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 50375\n",
      "    total_episode_count : 720\n",
      "\n",
      "                   iter : 37\n",
      "              mean_eval : 12.242144584655762\n",
      "          pop_best_eval : 36.54985046386719\n",
      "            median_eval : 6.958395957946777\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 51593\n",
      "    total_episode_count : 740\n",
      "\n",
      "                   iter : 38\n",
      "              mean_eval : 23.636762619018555\n",
      "          pop_best_eval : 107.37393188476562\n",
      "            median_eval : 9.987800598144531\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 53424\n",
      "    total_episode_count : 760\n",
      "\n",
      "                   iter : 39\n",
      "              mean_eval : 13.194132804870605\n",
      "          pop_best_eval : 72.00494384765625\n",
      "            median_eval : 9.068106651306152\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 54693\n",
      "    total_episode_count : 780\n",
      "\n",
      "                   iter : 40\n",
      "              mean_eval : 20.48598289489746\n",
      "          pop_best_eval : 85.77851104736328\n",
      "            median_eval : 9.193832397460938\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 56350\n",
      "    total_episode_count : 800\n",
      "\n",
      "                   iter : 41\n",
      "              mean_eval : 15.303875923156738\n",
      "          pop_best_eval : 74.14271545410156\n",
      "            median_eval : 9.010546684265137\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 57789\n",
      "    total_episode_count : 820\n",
      "\n",
      "                   iter : 42\n",
      "              mean_eval : 12.892555236816406\n",
      "          pop_best_eval : 48.43787384033203\n",
      "            median_eval : 7.068347454071045\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -44.87783432006836\n",
      "total_interaction_count : 59188\n",
      "    total_episode_count : 840\n",
      "\n",
      "                   iter : 43\n",
      "              mean_eval : 10.538838386535645\n",
      "          pop_best_eval : 83.79940795898438\n",
      "            median_eval : 8.71557903289795\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -95.84756469726562\n",
      "total_interaction_count : 60820\n",
      "    total_episode_count : 860\n",
      "\n",
      "                   iter : 44\n",
      "              mean_eval : 9.372861862182617\n",
      "          pop_best_eval : 21.325185775756836\n",
      "            median_eval : 8.003110885620117\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -95.84756469726562\n",
      "total_interaction_count : 61876\n",
      "    total_episode_count : 880\n",
      "\n",
      "                   iter : 45\n",
      "              mean_eval : 12.529266357421875\n",
      "          pop_best_eval : 27.797428131103516\n",
      "            median_eval : 8.66664981842041\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -95.84756469726562\n",
      "total_interaction_count : 63115\n",
      "    total_episode_count : 900\n",
      "\n",
      "                   iter : 46\n",
      "              mean_eval : 24.022985458374023\n",
      "          pop_best_eval : 107.75906372070312\n",
      "            median_eval : 8.358230590820312\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -95.84756469726562\n",
      "total_interaction_count : 64985\n",
      "    total_episode_count : 920\n",
      "\n",
      "                   iter : 47\n",
      "              mean_eval : 16.908817291259766\n",
      "          pop_best_eval : 81.45830535888672\n",
      "            median_eval : 10.644381523132324\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -95.84756469726562\n",
      "total_interaction_count : 66682\n",
      "    total_episode_count : 940\n",
      "\n",
      "                   iter : 48\n",
      "              mean_eval : 16.03277015686035\n",
      "          pop_best_eval : 55.0262336730957\n",
      "            median_eval : 11.211163520812988\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -95.84756469726562\n",
      "total_interaction_count : 68228\n",
      "    total_episode_count : 960\n",
      "\n",
      "                   iter : 49\n",
      "              mean_eval : 24.376977920532227\n",
      "          pop_best_eval : 84.41490173339844\n",
      "            median_eval : 11.240357398986816\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -95.84756469726562\n",
      "total_interaction_count : 70095\n",
      "    total_episode_count : 980\n",
      "\n",
      "                   iter : 50\n",
      "              mean_eval : 10.656930923461914\n",
      "          pop_best_eval : 63.060298919677734\n",
      "            median_eval : 8.072793006896973\n",
      "              best_eval : 107.90327453613281\n",
      "             worst_eval : -95.84756469726562\n",
      "total_interaction_count : 71210\n",
      "    total_episode_count : 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from evotorch.algorithms import SNES\n",
    "q_network = QNetwork(action_dim).to(device)\n",
    "problem = GymNE(\n",
    "    env=gymNE_env,\n",
    "    network=q_network,\n",
    "    num_episodes=1,\n",
    "    action_noise_stdev=0.1,\n",
    ")\n",
    "searcher = SNES(problem, stdev_init=5, popsize=20, popsize_max=40)\n",
    "StdOutLogger(searcher)\n",
    "searcher.run(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.625791735721206\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"EA_results/GymNE_2024-03-10-20.21.07_5548_generation000090.pickle\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "best = results[\"best\"]\n",
    "from policy import SimpleQNetwork\n",
    "q_network = SimpleQNetwork(action_dim)\n",
    "recover_flattened(best, q_network)\n",
    "torch.save(q_network, \"models/CMAES.pth\")\n",
    "# model = torch.load(\"models/CEM.pth\", map_location=device)\n",
    "env = CarEnv(300, display=True, evaluation=False, draw_central_line=True)\n",
    "\n",
    "obs = env.reset()\n",
    "score = 0\n",
    "\n",
    "while True:\n",
    "    obstensor = CarEnv.obs2tensor(obs, device)\n",
    "    action = q_network(obstensor).argmax(dim=1)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    score += reward\n",
    "    if done:\n",
    "        break\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On these two algorithms (SNES and CEM), the result is that the car is going straight forward. We must fine-tune this using longer time for each episode.\n",
    "We will also use a stronger noise for the road to force the policy to learn in difficult situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-10 20:03:30] INFO     <16244> evotorch.core: Instance of `GymNE` (id:2570471146192) -- The `dtype` for the problem's decision variables is set as torch.float32\n",
      "[2024-03-10 20:03:30] INFO     <16244> evotorch.core: Instance of `GymNE` (id:2570471146192) -- `eval_dtype` (the dtype of the fitnesses and evaluation data) is set as torch.float32\n",
      "[2024-03-10 20:03:30] INFO     <16244> evotorch.core: Instance of `GymNE` (id:2570471146192) -- The `device` of the problem is set as cpu\n",
      "[2024-03-10 20:03:30] INFO     <16244> evotorch.core: Instance of `GymNE` (id:2570471146192) -- The number of actors that will be allocated for parallelized evaluation is 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m StdOutLogger(searcher)\n\u001b[0;32m     12\u001b[0m PicklingLogger(searcher, interval\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, directory\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEA_results\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m searcher\u001b[39m.\u001b[39;49mrun(\u001b[39m100\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\algorithms\\searchalgorithm.py:425\u001b[0m, in \u001b[0;36mSearchAlgorithm.run\u001b[1;34m(self, num_generations, reset_first_step_datetime)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_first_step_datetime()\n\u001b[0;32m    424\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mint\u001b[39m(num_generations)):\n\u001b[1;32m--> 425\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    427\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_of_run_hook) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    428\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_of_run_hook(\u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus))\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\algorithms\\searchalgorithm.py:390\u001b[0m, in \u001b[0;36mSearchAlgorithm.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_step_datetime \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_step_datetime \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m--> 390\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step()\n\u001b[0;32m    391\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    392\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_status({\u001b[39m\"\u001b[39m\u001b[39miter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_count})\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\algorithms\\distributed\\gaussian.py:354\u001b[0m, in \u001b[0;36mGaussianSearchAlgorithm._step_non_distributed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_population \u001b[39m=\u001b[39m SolutionBatch\u001b[39m.\u001b[39mcat(populations)\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_iter:\n\u001b[0;32m    352\u001b[0m     \u001b[39m# If we are computing the first generation, we just sample from our distribution and evaluate\u001b[39;00m\n\u001b[0;32m    353\u001b[0m     \u001b[39m# the solutions.\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m     fill_and_eval_pop()\n\u001b[0;32m    355\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_iter \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[39m# If we are computing next generations, then we need to compute the gradients of the last\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[39m# generation, sample a new population, and evaluate the new population's solutions.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\algorithms\\distributed\\gaussian.py:295\u001b[0m, in \u001b[0;36mGaussianSearchAlgorithm._step_non_distributed.<locals>.fill_and_eval_pop\u001b[1;34m()\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution\u001b[39m.\u001b[39msample(out\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_population\u001b[39m.\u001b[39maccess_values(), generator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem)\n\u001b[0;32m    294\u001b[0m     \u001b[39m# Finally, here, the solutions are evaluated.\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproblem\u001b[39m.\u001b[39;49mevaluate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_population)\n\u001b[0;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m     \u001b[39m# If num_interactions is not None, then this means that we have a threshold for the number\u001b[39;00m\n\u001b[0;32m    298\u001b[0m     \u001b[39m# of simulator interactions to reach before declaring the phase of sampling complete.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[39m# Therefore, to properly count the simulator interactions we made during this generation, we need\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[39m# to get the interaction count before starting our sampling and evaluation operations.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m     first_num_interactions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem\u001b[39m.\u001b[39mstatus\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtotal_interaction_count\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\core.py:2548\u001b[0m, in \u001b[0;36mProblem.evaluate\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   2544\u001b[0m must_sync_after \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sync_before()\n\u001b[0;32m   2546\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_preparations()\n\u001b[1;32m-> 2548\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_all(batch)\n\u001b[0;32m   2550\u001b[0m \u001b[39mif\u001b[39;00m must_sync_after:\n\u001b[0;32m   2551\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sync_after()\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\core.py:2566\u001b[0m, in \u001b[0;36mProblem._evaluate_all\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m   2564\u001b[0m fitness_device \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device_of_fitness_function()\n\u001b[0;32m   2565\u001b[0m \u001b[39mif\u001b[39;00m fitness_device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2566\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_batch(batch)\n\u001b[0;32m   2567\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2568\u001b[0m     original_device \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mdevice\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\core.py:2600\u001b[0m, in \u001b[0;36mProblem._evaluate_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m   2598\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2599\u001b[0m     \u001b[39mfor\u001b[39;00m sln \u001b[39min\u001b[39;00m batch:\n\u001b[1;32m-> 2600\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate(sln)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\neproblem.py:424\u001b[0m, in \u001b[0;36mNEProblem._evaluate\u001b[1;34m(self, solution)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     evaluator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_eval_func\n\u001b[1;32m--> 424\u001b[0m fitnesses \u001b[39m=\u001b[39m evaluator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparameterize_net(parameters))\n\u001b[0;32m    426\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fitnesses, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    427\u001b[0m     solution\u001b[39m.\u001b[39mset_evals(\u001b[39m*\u001b[39mfitnesses)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\gymne.py:637\u001b[0m, in \u001b[0;36mGymNE._evaluate_network\u001b[1;34m(self, policy)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_evaluate_network\u001b[39m(\u001b[39mself\u001b[39m, policy: nn\u001b[39m.\u001b[39mModule) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[\u001b[39mfloat\u001b[39m, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 637\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m    638\u001b[0m         policy,\n\u001b[0;32m    639\u001b[0m         update_stats\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    640\u001b[0m         visualize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    641\u001b[0m         num_episodes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_episodes,\n\u001b[0;32m    642\u001b[0m         decrease_rewards_by\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decrease_rewards_by,\n\u001b[0;32m    643\u001b[0m     )\n\u001b[0;32m    644\u001b[0m     \u001b[39mreturn\u001b[39;00m result[\u001b[39m\"\u001b[39m\u001b[39mcumulative_reward\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\gymne.py:462\u001b[0m, in \u001b[0;36mGymNE.run\u001b[1;34m(self, policy, update_stats, visualize, num_episodes, decrease_rewards_by)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     policy\u001b[39m.\u001b[39meval()\n\u001b[1;32m--> 462\u001b[0m     episode_results \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rollout(\n\u001b[0;32m    464\u001b[0m             policy\u001b[39m=\u001b[39;49mpolicy,\n\u001b[0;32m    465\u001b[0m             update_stats\u001b[39m=\u001b[39;49mupdate_stats,\n\u001b[0;32m    466\u001b[0m             visualize\u001b[39m=\u001b[39;49mvisualize,\n\u001b[0;32m    467\u001b[0m             decrease_rewards_by\u001b[39m=\u001b[39;49mdecrease_rewards_by,\n\u001b[0;32m    468\u001b[0m         )\n\u001b[0;32m    469\u001b[0m         \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(num_episodes)\n\u001b[0;32m    470\u001b[0m     ]\n\u001b[0;32m    472\u001b[0m     results \u001b[39m=\u001b[39m _accumulate_all_across_dicts(episode_results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_keys)\n\u001b[0;32m    473\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\gymne.py:463\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     policy\u001b[39m.\u001b[39meval()\n\u001b[0;32m    462\u001b[0m     episode_results \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rollout(\n\u001b[0;32m    464\u001b[0m             policy\u001b[39m=\u001b[39;49mpolicy,\n\u001b[0;32m    465\u001b[0m             update_stats\u001b[39m=\u001b[39;49mupdate_stats,\n\u001b[0;32m    466\u001b[0m             visualize\u001b[39m=\u001b[39;49mvisualize,\n\u001b[0;32m    467\u001b[0m             decrease_rewards_by\u001b[39m=\u001b[39;49mdecrease_rewards_by,\n\u001b[0;32m    468\u001b[0m         )\n\u001b[0;32m    469\u001b[0m         \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_episodes)\n\u001b[0;32m    470\u001b[0m     ]\n\u001b[0;32m    472\u001b[0m     results \u001b[39m=\u001b[39m _accumulate_all_across_dicts(episode_results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_keys)\n\u001b[0;32m    473\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\gymne.py:391\u001b[0m, in \u001b[0;36mGymNE._rollout\u001b[1;34m(self, policy, update_stats, visualize, decrease_rewards_by)\u001b[0m\n\u001b[0;32m    388\u001b[0m cumulative_reward \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m    390\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m     observation, raw_reward, done, info \u001b[39m=\u001b[39m take_step_in_env(env, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_use_policy(observation, policy))\n\u001b[0;32m    392\u001b[0m     reward \u001b[39m=\u001b[39m raw_reward \u001b[39m-\u001b[39m decrease_rewards_by\n\u001b[0;32m    393\u001b[0m     t \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\.venv\\Lib\\site-packages\\evotorch\\neuroevolution\\net\\rl.py:105\u001b[0m, in \u001b[0;36mtake_step_in_env\u001b[1;34m(env, action)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtake_step_in_env\u001b[39m(env: gym\u001b[39m.\u001b[39mEnv, action: Iterable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m:\n\u001b[0;32m     84\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[39m    Take a step in the gymnasium environment.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39m    Taking a step means performing the action provided via the arguments.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m        `info` is additional information (usually as a dictionary).\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     result \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m    106\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    107\u001b[0m         n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\environment.py:241\u001b[0m, in \u001b[0;36mTorchLikeCarEnv.step\u001b[1;34m(self, action, dt)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action, dt\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m\u001b[39m/\u001b[39m\u001b[39m30\u001b[39m):\n\u001b[0;32m    240\u001b[0m     obs, rwrd, done, info \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mstep(action, dt)\n\u001b[1;32m--> 241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobs2tensor(obs), rwrd, done, info\n",
      "File \u001b[1;32mc:\\Users\\bcbav\\.vscode\\environnement_ipython\\INF581\\car_project\\Projet\\environment.py:229\u001b[0m, in \u001b[0;36mCarEnv.obs2tensor\u001b[1;34m(obs, device)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m device:\n\u001b[0;32m    227\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\n\u001b[0;32m    228\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(obs[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m], np\u001b[39m.\u001b[39muint8)):\n\u001b[0;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(obs, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    231\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from evotorch.algorithms import SNES\n",
    "def gymNE_env(*args, **kwargs): return TorchLikeCarEnv(30, True, evaluation=False, scale=0.002, persistence=0.01, *args, **kwargs)\n",
    "q_network = torch.load(\"models/SNES1.pth\", map_location=device)\n",
    "problem = GymNE(\n",
    "    env=gymNE_env,\n",
    "    network=q_network,\n",
    "    num_episodes=1,\n",
    "    action_noise_stdev=0.1,\n",
    ")\n",
    "searcher = SNES(problem, stdev_init=5, popsize=20, popsize_max=40)\n",
    "StdOutLogger(searcher)\n",
    "PicklingLogger(searcher, interval=10, directory=\"EA_results\")\n",
    "searcher.run(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results tend to be worse...\n",
    "\n",
    "=> alive_bonus_schedule to force long term reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-10 20:21:02] INFO     < 5548> evotorch.core: Instance of `GymNE` (id:1793141663504) -- The `dtype` for the problem's decision variables is set as torch.float32\n",
      "[2024-03-10 20:21:02] INFO     < 5548> evotorch.core: Instance of `GymNE` (id:1793141663504) -- `eval_dtype` (the dtype of the fitnesses and evaluation data) is set as torch.float32\n",
      "[2024-03-10 20:21:02] INFO     < 5548> evotorch.core: Instance of `GymNE` (id:1793141663504) -- The `device` of the problem is set as cpu\n",
      "[2024-03-10 20:21:02] INFO     < 5548> evotorch.core: Instance of `GymNE` (id:1793141663504) -- The number of actors that will be allocated for parallelized evaluation is 0\n",
      "(15_w,31)-aCMA-ES (mu_w=8.9,w_1=20%) in dimension 10838 (seed=3690875053, Sun Mar 10 20:21:07 2024)\n",
      "                   iter : 1\n",
      "              mean_eval : 0.3022964298725128\n",
      "            median_eval : -2.4058985710144043\n",
      "          pop_best_eval : 45.930137634277344\n",
      "              best_eval : 45.930137634277344\n",
      "             worst_eval : -10.666427612304688\n",
      "total_interaction_count : 1420\n",
      "    total_episode_count : 31\n",
      "\n",
      "                   iter : 2\n",
      "              mean_eval : 4.1506571769714355\n",
      "            median_eval : 4.142824649810791\n",
      "          pop_best_eval : 70.9234848022461\n",
      "              best_eval : 70.9234848022461\n",
      "             worst_eval : -20.743785858154297\n",
      "total_interaction_count : 3151\n",
      "    total_episode_count : 62\n",
      "\n",
      "                   iter : 3\n",
      "              mean_eval : 4.264301776885986\n",
      "            median_eval : 4.913973331451416\n",
      "          pop_best_eval : 40.31633377075195\n",
      "              best_eval : 70.9234848022461\n",
      "             worst_eval : -20.743785858154297\n",
      "total_interaction_count : 4595\n",
      "    total_episode_count : 93\n",
      "\n",
      "                   iter : 4\n",
      "              mean_eval : 11.764653205871582\n",
      "            median_eval : 6.176122188568115\n",
      "          pop_best_eval : 125.98788452148438\n",
      "              best_eval : 125.98788452148438\n",
      "             worst_eval : -20.743785858154297\n",
      "total_interaction_count : 6681\n",
      "    total_episode_count : 124\n",
      "\n",
      "                   iter : 5\n",
      "              mean_eval : 5.121832847595215\n",
      "            median_eval : 5.621268272399902\n",
      "          pop_best_eval : 128.2672882080078\n",
      "              best_eval : 128.2672882080078\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 8715\n",
      "    total_episode_count : 155\n",
      "\n",
      "                   iter : 6\n",
      "              mean_eval : 15.671242713928223\n",
      "            median_eval : 6.052137851715088\n",
      "          pop_best_eval : 125.86375427246094\n",
      "              best_eval : 128.2672882080078\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 11401\n",
      "    total_episode_count : 186\n",
      "\n",
      "                   iter : 7\n",
      "              mean_eval : 17.535146713256836\n",
      "            median_eval : 7.160953044891357\n",
      "          pop_best_eval : 122.19017028808594\n",
      "              best_eval : 128.2672882080078\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 13876\n",
      "    total_episode_count : 217\n",
      "\n",
      "                   iter : 8\n",
      "              mean_eval : 8.828204154968262\n",
      "            median_eval : 7.309686183929443\n",
      "          pop_best_eval : 62.5768928527832\n",
      "              best_eval : 128.2672882080078\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 15838\n",
      "    total_episode_count : 248\n",
      "\n",
      "                   iter : 9\n",
      "              mean_eval : 16.0975284576416\n",
      "            median_eval : 7.730827331542969\n",
      "          pop_best_eval : 73.80033111572266\n",
      "              best_eval : 128.2672882080078\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 18221\n",
      "    total_episode_count : 279\n",
      "\n",
      "                   iter : 10\n",
      "              mean_eval : 24.579999923706055\n",
      "            median_eval : 10.495667457580566\n",
      "          pop_best_eval : 158.8234100341797\n",
      "              best_eval : 158.8234100341797\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 21128\n",
      "    total_episode_count : 310\n",
      "\n",
      "Saved to EA_results\\GymNE_2024-03-10-20.21.07_5548_generation000010.pickle\n",
      "                   iter : 11\n",
      "              mean_eval : 22.925500869750977\n",
      "            median_eval : 12.88798713684082\n",
      "          pop_best_eval : 108.35693359375\n",
      "              best_eval : 158.8234100341797\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 23937\n",
      "    total_episode_count : 341\n",
      "\n",
      "                   iter : 12\n",
      "              mean_eval : 16.577194213867188\n",
      "            median_eval : 8.890091896057129\n",
      "          pop_best_eval : 109.9885025024414\n",
      "              best_eval : 158.8234100341797\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 26350\n",
      "    total_episode_count : 372\n",
      "\n",
      "                   iter : 13\n",
      "              mean_eval : 17.57215118408203\n",
      "            median_eval : 6.621474742889404\n",
      "          pop_best_eval : 241.53945922851562\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 28721\n",
      "    total_episode_count : 403\n",
      "\n",
      "                   iter : 14\n",
      "              mean_eval : 13.12541675567627\n",
      "            median_eval : 8.869499206542969\n",
      "          pop_best_eval : 92.84705352783203\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 30730\n",
      "    total_episode_count : 434\n",
      "\n",
      "                   iter : 15\n",
      "              mean_eval : 14.33208179473877\n",
      "            median_eval : 7.839051246643066\n",
      "          pop_best_eval : 80.8006591796875\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 32829\n",
      "    total_episode_count : 465\n",
      "\n",
      "                   iter : 16\n",
      "              mean_eval : 16.400081634521484\n",
      "            median_eval : 8.542611122131348\n",
      "          pop_best_eval : 108.93949127197266\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 35321\n",
      "    total_episode_count : 496\n",
      "\n",
      "                   iter : 17\n",
      "              mean_eval : 10.206090927124023\n",
      "            median_eval : 7.532186985015869\n",
      "          pop_best_eval : 41.59928894042969\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 37083\n",
      "    total_episode_count : 527\n",
      "\n",
      "                   iter : 18\n",
      "              mean_eval : 16.688369750976562\n",
      "            median_eval : 9.185887336730957\n",
      "          pop_best_eval : 81.56558227539062\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 39329\n",
      "    total_episode_count : 558\n",
      "\n",
      "                   iter : 19\n",
      "              mean_eval : 15.973981857299805\n",
      "            median_eval : 7.169182777404785\n",
      "          pop_best_eval : 92.18858337402344\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 41631\n",
      "    total_episode_count : 589\n",
      "\n",
      "                   iter : 20\n",
      "              mean_eval : 12.282797813415527\n",
      "            median_eval : 6.558907985687256\n",
      "          pop_best_eval : 73.37293243408203\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 43541\n",
      "    total_episode_count : 620\n",
      "\n",
      "Saved to EA_results\\GymNE_2024-03-10-20.21.07_5548_generation000020.pickle\n",
      "                   iter : 21\n",
      "              mean_eval : 20.354764938354492\n",
      "            median_eval : 8.229891777038574\n",
      "          pop_best_eval : 135.23898315429688\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 46236\n",
      "    total_episode_count : 651\n",
      "\n",
      "                   iter : 22\n",
      "              mean_eval : 23.067928314208984\n",
      "            median_eval : 10.345638275146484\n",
      "          pop_best_eval : 144.3514862060547\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 48996\n",
      "    total_episode_count : 682\n",
      "\n",
      "                   iter : 23\n",
      "              mean_eval : 32.09479904174805\n",
      "            median_eval : 17.60279083251953\n",
      "          pop_best_eval : 202.24249267578125\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 52677\n",
      "    total_episode_count : 713\n",
      "\n",
      "                   iter : 24\n",
      "              mean_eval : 11.624467849731445\n",
      "            median_eval : 7.104130744934082\n",
      "          pop_best_eval : 50.448062896728516\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 54529\n",
      "    total_episode_count : 744\n",
      "\n",
      "                   iter : 25\n",
      "              mean_eval : 12.432851791381836\n",
      "            median_eval : 8.090660095214844\n",
      "          pop_best_eval : 73.89849090576172\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 56428\n",
      "    total_episode_count : 775\n",
      "\n",
      "                   iter : 26\n",
      "              mean_eval : 16.253864288330078\n",
      "            median_eval : 11.245824813842773\n",
      "          pop_best_eval : 72.90428924560547\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 58666\n",
      "    total_episode_count : 806\n",
      "\n",
      "                   iter : 27\n",
      "              mean_eval : 18.69447135925293\n",
      "            median_eval : 11.216414451599121\n",
      "          pop_best_eval : 115.94458770751953\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 61146\n",
      "    total_episode_count : 837\n",
      "\n",
      "                   iter : 28\n",
      "              mean_eval : 15.955124855041504\n",
      "            median_eval : 10.16594409942627\n",
      "          pop_best_eval : 78.29146575927734\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 63350\n",
      "    total_episode_count : 868\n",
      "\n",
      "                   iter : 29\n",
      "              mean_eval : 25.084186553955078\n",
      "            median_eval : 11.152966499328613\n",
      "          pop_best_eval : 183.255859375\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 66334\n",
      "    total_episode_count : 899\n",
      "\n",
      "                   iter : 30\n",
      "              mean_eval : 19.302051544189453\n",
      "            median_eval : 8.84280014038086\n",
      "          pop_best_eval : 148.95724487304688\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 68997\n",
      "    total_episode_count : 930\n",
      "\n",
      "Saved to EA_results\\GymNE_2024-03-10-20.21.07_5548_generation000030.pickle\n",
      "                   iter : 31\n",
      "              mean_eval : 12.765748977661133\n",
      "            median_eval : 8.7674560546875\n",
      "          pop_best_eval : 50.26729965209961\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 70992\n",
      "    total_episode_count : 961\n",
      "\n",
      "                   iter : 32\n",
      "              mean_eval : 17.879554748535156\n",
      "            median_eval : 11.967004776000977\n",
      "          pop_best_eval : 111.82719421386719\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 73602\n",
      "    total_episode_count : 992\n",
      "\n",
      "                   iter : 33\n",
      "              mean_eval : 15.274444580078125\n",
      "            median_eval : 8.984208106994629\n",
      "          pop_best_eval : 100.64910125732422\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 75891\n",
      "    total_episode_count : 1023\n",
      "\n",
      "                   iter : 34\n",
      "              mean_eval : 16.21095085144043\n",
      "            median_eval : 10.965426445007324\n",
      "          pop_best_eval : 57.334815979003906\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 78127\n",
      "    total_episode_count : 1054\n",
      "\n",
      "                   iter : 35\n",
      "              mean_eval : 17.851634979248047\n",
      "            median_eval : 10.8605318069458\n",
      "          pop_best_eval : 81.1640625\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 80508\n",
      "    total_episode_count : 1085\n",
      "\n",
      "                   iter : 36\n",
      "              mean_eval : 9.467437744140625\n",
      "            median_eval : 8.082052230834961\n",
      "          pop_best_eval : 38.66037368774414\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 82173\n",
      "    total_episode_count : 1116\n",
      "\n",
      "                   iter : 37\n",
      "              mean_eval : 23.049264907836914\n",
      "            median_eval : 8.891609191894531\n",
      "          pop_best_eval : 201.2467498779297\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 85278\n",
      "    total_episode_count : 1147\n",
      "\n",
      "                   iter : 38\n",
      "              mean_eval : 12.866249084472656\n",
      "            median_eval : 9.195996284484863\n",
      "          pop_best_eval : 39.91509246826172\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 87248\n",
      "    total_episode_count : 1178\n",
      "\n",
      "                   iter : 39\n",
      "              mean_eval : 22.812074661254883\n",
      "            median_eval : 7.256050109863281\n",
      "          pop_best_eval : 155.9009246826172\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 90053\n",
      "    total_episode_count : 1209\n",
      "\n",
      "                   iter : 40\n",
      "              mean_eval : 19.403146743774414\n",
      "            median_eval : 8.045259475708008\n",
      "          pop_best_eval : 79.70771026611328\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 92785\n",
      "    total_episode_count : 1240\n",
      "\n",
      "Saved to EA_results\\GymNE_2024-03-10-20.21.07_5548_generation000040.pickle\n",
      "                   iter : 41\n",
      "              mean_eval : 20.91701316833496\n",
      "            median_eval : 7.497046947479248\n",
      "          pop_best_eval : 133.99368286132812\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 95455\n",
      "    total_episode_count : 1271\n",
      "\n",
      "                   iter : 42\n",
      "              mean_eval : 18.050825119018555\n",
      "            median_eval : 8.084086418151855\n",
      "          pop_best_eval : 126.55540466308594\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 97944\n",
      "    total_episode_count : 1302\n",
      "\n",
      "                   iter : 43\n",
      "              mean_eval : 16.54496955871582\n",
      "            median_eval : 7.968111515045166\n",
      "          pop_best_eval : 82.39044189453125\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 100208\n",
      "    total_episode_count : 1333\n",
      "\n",
      "                   iter : 44\n",
      "              mean_eval : 14.551923751831055\n",
      "            median_eval : 12.385668754577637\n",
      "          pop_best_eval : 89.47113037109375\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 102733\n",
      "    total_episode_count : 1364\n",
      "\n",
      "                   iter : 45\n",
      "              mean_eval : 16.587215423583984\n",
      "            median_eval : 12.689191818237305\n",
      "          pop_best_eval : 58.1976432800293\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 104996\n",
      "    total_episode_count : 1395\n",
      "\n",
      "                   iter : 46\n",
      "              mean_eval : 23.1700496673584\n",
      "            median_eval : 10.226969718933105\n",
      "          pop_best_eval : 109.63837432861328\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 107755\n",
      "    total_episode_count : 1426\n",
      "\n",
      "                   iter : 47\n",
      "              mean_eval : 19.720706939697266\n",
      "            median_eval : 8.080795288085938\n",
      "          pop_best_eval : 109.6275863647461\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 110245\n",
      "    total_episode_count : 1457\n",
      "\n",
      "                   iter : 48\n",
      "              mean_eval : 14.760664939880371\n",
      "            median_eval : 9.852941513061523\n",
      "          pop_best_eval : 46.42504119873047\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 112379\n",
      "    total_episode_count : 1488\n",
      "\n",
      "                   iter : 49\n",
      "              mean_eval : 21.426612854003906\n",
      "            median_eval : 14.754344940185547\n",
      "          pop_best_eval : 110.43547821044922\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 115074\n",
      "    total_episode_count : 1519\n",
      "\n",
      "                   iter : 50\n",
      "              mean_eval : 17.853660583496094\n",
      "            median_eval : 10.522448539733887\n",
      "          pop_best_eval : 69.15278625488281\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 117419\n",
      "    total_episode_count : 1550\n",
      "\n",
      "Saved to EA_results\\GymNE_2024-03-10-20.21.07_5548_generation000050.pickle\n",
      "                   iter : 51\n",
      "              mean_eval : 24.72498893737793\n",
      "            median_eval : 9.782896041870117\n",
      "          pop_best_eval : 186.2698516845703\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 120364\n",
      "    total_episode_count : 1581\n",
      "\n",
      "                   iter : 52\n",
      "              mean_eval : 20.96245574951172\n",
      "            median_eval : 14.439508438110352\n",
      "          pop_best_eval : 107.6854248046875\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 123141\n",
      "    total_episode_count : 1612\n",
      "\n",
      "                   iter : 53\n",
      "              mean_eval : 16.571016311645508\n",
      "            median_eval : 9.328605651855469\n",
      "          pop_best_eval : 110.16673278808594\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 125430\n",
      "    total_episode_count : 1643\n",
      "\n",
      "                   iter : 54\n",
      "              mean_eval : 11.226438522338867\n",
      "            median_eval : 8.210926055908203\n",
      "          pop_best_eval : 56.27519989013672\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 127370\n",
      "    total_episode_count : 1674\n",
      "\n",
      "                   iter : 55\n",
      "              mean_eval : 20.252761840820312\n",
      "            median_eval : 9.052691459655762\n",
      "          pop_best_eval : 118.4732894897461\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 129911\n",
      "    total_episode_count : 1705\n",
      "\n",
      "                   iter : 56\n",
      "              mean_eval : 12.405619621276855\n",
      "            median_eval : 8.858123779296875\n",
      "          pop_best_eval : 58.80617141723633\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 131822\n",
      "    total_episode_count : 1736\n",
      "\n",
      "                   iter : 57\n",
      "              mean_eval : 18.83984375\n",
      "            median_eval : 6.799330234527588\n",
      "          pop_best_eval : 139.62950134277344\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 134294\n",
      "    total_episode_count : 1767\n",
      "\n",
      "                   iter : 58\n",
      "              mean_eval : 21.519798278808594\n",
      "            median_eval : 10.41995906829834\n",
      "          pop_best_eval : 96.87345886230469\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 136948\n",
      "    total_episode_count : 1798\n",
      "\n",
      "                   iter : 59\n",
      "              mean_eval : 15.930581092834473\n",
      "            median_eval : 8.246929168701172\n",
      "          pop_best_eval : 77.40445709228516\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 139240\n",
      "    total_episode_count : 1829\n",
      "\n",
      "                   iter : 60\n",
      "              mean_eval : 19.563425064086914\n",
      "            median_eval : 9.66081714630127\n",
      "          pop_best_eval : 163.5427703857422\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 141732\n",
      "    total_episode_count : 1860\n",
      "\n",
      "Saved to EA_results\\GymNE_2024-03-10-20.21.07_5548_generation000060.pickle\n",
      "                   iter : 61\n",
      "              mean_eval : 22.267627716064453\n",
      "            median_eval : 9.191834449768066\n",
      "          pop_best_eval : 150.72987365722656\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 144436\n",
      "    total_episode_count : 1891\n",
      "\n",
      "                   iter : 62\n",
      "              mean_eval : 15.540616035461426\n",
      "            median_eval : 9.08564281463623\n",
      "          pop_best_eval : 64.93428802490234\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 146881\n",
      "    total_episode_count : 1922\n",
      "\n",
      "                   iter : 63\n",
      "              mean_eval : 18.09513282775879\n",
      "            median_eval : 7.973464012145996\n",
      "          pop_best_eval : 72.62010955810547\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 149258\n",
      "    total_episode_count : 1953\n",
      "\n",
      "                   iter : 64\n",
      "              mean_eval : 22.922061920166016\n",
      "            median_eval : 8.956592559814453\n",
      "          pop_best_eval : 201.96426391601562\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 152073\n",
      "    total_episode_count : 1984\n",
      "\n",
      "                   iter : 65\n",
      "              mean_eval : 14.196686744689941\n",
      "            median_eval : 9.148233413696289\n",
      "          pop_best_eval : 49.57486343383789\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 154319\n",
      "    total_episode_count : 2015\n",
      "\n",
      "                   iter : 66\n",
      "              mean_eval : 18.8529109954834\n",
      "            median_eval : 9.982995986938477\n",
      "          pop_best_eval : 91.18000030517578\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 156921\n",
      "    total_episode_count : 2046\n",
      "\n",
      "                   iter : 67\n",
      "              mean_eval : 19.024276733398438\n",
      "            median_eval : 8.986875534057617\n",
      "          pop_best_eval : 84.12042236328125\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 159385\n",
      "    total_episode_count : 2077\n",
      "\n",
      "                   iter : 68\n",
      "              mean_eval : 17.20166015625\n",
      "            median_eval : 10.508600234985352\n",
      "          pop_best_eval : 76.64047241210938\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 161670\n",
      "    total_episode_count : 2108\n",
      "\n",
      "                   iter : 69\n",
      "              mean_eval : 18.970319747924805\n",
      "            median_eval : 14.338454246520996\n",
      "          pop_best_eval : 50.76530838012695\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 164151\n",
      "    total_episode_count : 2139\n",
      "\n",
      "                   iter : 70\n",
      "              mean_eval : 13.696802139282227\n",
      "            median_eval : 7.374729633331299\n",
      "          pop_best_eval : 83.49398040771484\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 166289\n",
      "    total_episode_count : 2170\n",
      "\n",
      "Saved to EA_results\\GymNE_2024-03-10-20.21.07_5548_generation000070.pickle\n",
      "                   iter : 71\n",
      "              mean_eval : 29.938329696655273\n",
      "            median_eval : 13.788935661315918\n",
      "          pop_best_eval : 196.01812744140625\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 169617\n",
      "    total_episode_count : 2201\n",
      "\n",
      "                   iter : 72\n",
      "              mean_eval : 16.954111099243164\n",
      "            median_eval : 8.069584846496582\n",
      "          pop_best_eval : 111.2550277709961\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 172037\n",
      "    total_episode_count : 2232\n",
      "\n",
      "                   iter : 73\n",
      "              mean_eval : 21.866474151611328\n",
      "            median_eval : 10.425436973571777\n",
      "          pop_best_eval : 154.50096130371094\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 174695\n",
      "    total_episode_count : 2263\n",
      "\n",
      "                   iter : 74\n",
      "              mean_eval : 18.30465316772461\n",
      "            median_eval : 7.917688846588135\n",
      "          pop_best_eval : 102.28062438964844\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 177273\n",
      "    total_episode_count : 2294\n",
      "\n",
      "                   iter : 75\n",
      "              mean_eval : 21.075340270996094\n",
      "            median_eval : 9.775925636291504\n",
      "          pop_best_eval : 114.68621063232422\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 179899\n",
      "    total_episode_count : 2325\n",
      "\n",
      "                   iter : 76\n",
      "              mean_eval : 21.4917049407959\n",
      "            median_eval : 9.979803085327148\n",
      "          pop_best_eval : 101.78611755371094\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 182684\n",
      "    total_episode_count : 2356\n",
      "\n",
      "                   iter : 77\n",
      "              mean_eval : 15.680634498596191\n",
      "            median_eval : 7.476546287536621\n",
      "          pop_best_eval : 58.09515380859375\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 185059\n",
      "    total_episode_count : 2387\n",
      "\n",
      "                   iter : 78\n",
      "              mean_eval : 15.214788436889648\n",
      "            median_eval : 8.055147171020508\n",
      "          pop_best_eval : 78.85104370117188\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 187182\n",
      "    total_episode_count : 2418\n",
      "\n",
      "                   iter : 79\n",
      "              mean_eval : 24.289011001586914\n",
      "            median_eval : 14.02032470703125\n",
      "          pop_best_eval : 132.4789581298828\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 190169\n",
      "    total_episode_count : 2449\n",
      "\n",
      "                   iter : 80\n",
      "              mean_eval : 19.15097999572754\n",
      "            median_eval : 10.685328483581543\n",
      "          pop_best_eval : 103.29045104980469\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 192637\n",
      "    total_episode_count : 2480\n",
      "\n",
      "Saved to EA_results\\GymNE_2024-03-10-20.21.07_5548_generation000080.pickle\n",
      "                   iter : 81\n",
      "              mean_eval : 19.27579116821289\n",
      "            median_eval : 8.759488105773926\n",
      "          pop_best_eval : 217.55030822753906\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 195149\n",
      "    total_episode_count : 2511\n",
      "\n",
      "                   iter : 82\n",
      "              mean_eval : 17.81993293762207\n",
      "            median_eval : 9.575257301330566\n",
      "          pop_best_eval : 83.95030975341797\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 197536\n",
      "    total_episode_count : 2542\n",
      "\n",
      "                   iter : 83\n",
      "              mean_eval : 14.923312187194824\n",
      "            median_eval : 7.185048580169678\n",
      "          pop_best_eval : 77.77631378173828\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 199795\n",
      "    total_episode_count : 2573\n",
      "\n",
      "                   iter : 84\n",
      "              mean_eval : 17.022523880004883\n",
      "            median_eval : 11.885111808776855\n",
      "          pop_best_eval : 45.77043533325195\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 202146\n",
      "    total_episode_count : 2604\n",
      "\n",
      "                   iter : 85\n",
      "              mean_eval : 15.311366081237793\n",
      "            median_eval : 8.729751586914062\n",
      "          pop_best_eval : 77.81865692138672\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 204286\n",
      "    total_episode_count : 2635\n",
      "\n",
      "                   iter : 86\n",
      "              mean_eval : 15.469889640808105\n",
      "            median_eval : 7.886068820953369\n",
      "          pop_best_eval : 61.44740295410156\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 206429\n",
      "    total_episode_count : 2666\n",
      "\n",
      "                   iter : 87\n",
      "              mean_eval : 15.83916187286377\n",
      "            median_eval : 9.498260498046875\n",
      "          pop_best_eval : 61.201202392578125\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 208648\n",
      "    total_episode_count : 2697\n",
      "\n",
      "                   iter : 88\n",
      "              mean_eval : 17.479228973388672\n",
      "            median_eval : 9.306800842285156\n",
      "          pop_best_eval : 127.76885986328125\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 210999\n",
      "    total_episode_count : 2728\n",
      "\n",
      "                   iter : 89\n",
      "              mean_eval : 13.266695022583008\n",
      "            median_eval : 7.370595932006836\n",
      "          pop_best_eval : 104.1214370727539\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 212990\n",
      "    total_episode_count : 2759\n",
      "\n",
      "                   iter : 90\n",
      "              mean_eval : 20.072914123535156\n",
      "            median_eval : 9.386499404907227\n",
      "          pop_best_eval : 94.98767852783203\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 215748\n",
      "    total_episode_count : 2790\n",
      "\n",
      "Saved to EA_results\\GymNE_2024-03-10-20.21.07_5548_generation000090.pickle\n",
      "                   iter : 91\n",
      "              mean_eval : 21.04747772216797\n",
      "            median_eval : 10.84555435180664\n",
      "          pop_best_eval : 101.2313461303711\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 218436\n",
      "    total_episode_count : 2821\n",
      "\n",
      "                   iter : 92\n",
      "              mean_eval : 15.628445625305176\n",
      "            median_eval : 9.16063404083252\n",
      "          pop_best_eval : 71.03510284423828\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 220615\n",
      "    total_episode_count : 2852\n",
      "\n",
      "                   iter : 93\n",
      "              mean_eval : 21.405988693237305\n",
      "            median_eval : 8.049903869628906\n",
      "          pop_best_eval : 107.68266296386719\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 223220\n",
      "    total_episode_count : 2883\n",
      "\n",
      "                   iter : 94\n",
      "              mean_eval : 14.526261329650879\n",
      "            median_eval : 9.319253921508789\n",
      "          pop_best_eval : 62.53926467895508\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 225307\n",
      "    total_episode_count : 2914\n",
      "\n",
      "                   iter : 95\n",
      "              mean_eval : 24.290292739868164\n",
      "            median_eval : 11.514625549316406\n",
      "          pop_best_eval : 84.96744537353516\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 228229\n",
      "    total_episode_count : 2945\n",
      "\n",
      "                   iter : 96\n",
      "              mean_eval : 19.863265991210938\n",
      "            median_eval : 10.072141647338867\n",
      "          pop_best_eval : 121.21112060546875\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 230923\n",
      "    total_episode_count : 2976\n",
      "\n",
      "                   iter : 97\n",
      "              mean_eval : 18.089563369750977\n",
      "            median_eval : 11.721660614013672\n",
      "          pop_best_eval : 74.1568374633789\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 233329\n",
      "    total_episode_count : 3007\n",
      "\n",
      "                   iter : 98\n",
      "              mean_eval : 23.612743377685547\n",
      "            median_eval : 8.414074897766113\n",
      "          pop_best_eval : 167.20811462402344\n",
      "              best_eval : 241.53945922851562\n",
      "             worst_eval : -70.33954620361328\n",
      "total_interaction_count : 236202\n",
      "    total_episode_count : 3038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from policy import SimpleQNetwork\n",
    "from evotorch.algorithms import PyCMAES\n",
    "\n",
    "def gymNE_env(*args, **kwargs): return TorchLikeCarEnv(30, False, evaluation=False, scale=0.002, persistence=0.01, *args, **kwargs)\n",
    "q_network =torch.load(\"models/CMAES.pth\", map_location=device)\n",
    "problem = GymNE(\n",
    "    env=gymNE_env,\n",
    "    network=q_network,\n",
    "    num_episodes=1,\n",
    ")\n",
    "searcher = PyCMAES(problem, stdev_init=5)\n",
    "StdOutLogger(searcher)\n",
    "PicklingLogger(searcher, interval=10, directory=\"EA_results\")\n",
    "searcher.run(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
